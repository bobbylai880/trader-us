#!/usr/bin/env python3
"""
åŽ†å²å›žæµ‹ç‰ˆæƒ…æŠ¥åˆ†æžå™¨

åŸºäºŽåŽ†å²äº‹ä»¶æ—¶é—´çº¿ï¼Œä¸ºæ¯ä¸ªå­£åº¦ç”ŸæˆæŠ•èµ„ä¸»é¢˜é…ç½®ã€‚
æ”¯æŒä¸¤ç§æ¨¡å¼:
1. è§„åˆ™å›žé€€æ¨¡å¼: åŸºäºŽå…³é”®è¯åŒ¹é…å¿«é€Ÿç”Ÿæˆ
2. LLMåˆ†æžæ¨¡å¼: ä½¿ç”¨ Claude/DeepSeek æ·±åº¦åˆ†æž

ç”¨äºŽ V7.1 å›žæµ‹éªŒè¯ LLM åˆ†æžçš„æœ‰æ•ˆæ€§ã€‚
"""

from __future__ import annotations

import json
import os
import re
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any

from .historical_events import HISTORICAL_EVENTS, get_quarter_events, get_all_quarters


@dataclass
class QuarterTheme:
    """å­£åº¦æŠ•èµ„ä¸»é¢˜é…ç½®"""
    quarter: str
    theme: str
    focus_sectors: List[str]
    focus_stocks: List[str]
    avoid_sectors: List[str]
    sector_bonus: Dict[str, int]
    confidence: str  # high/medium/low
    reasoning: str
    source: str  # "rule" or "llm"


# æ¿å—é¾™å¤´è‚¡æ˜ å°„
SECTOR_LEADERS = {
    "XLK": ["NVDA", "AAPL", "MSFT", "AVGO", "AMD", "ADBE", "CRM", "ORCL"],
    "XLC": ["META", "GOOGL", "NFLX", "DIS", "TMUS"],
    "XLY": ["AMZN", "TSLA", "HD", "MCD", "NKE", "SBUX"],
    "XLF": ["JPM", "BAC", "WFC", "GS", "MS", "BLK"],
    "XLV": ["UNH", "LLY", "JNJ", "PFE", "MRK", "ABBV"],
    "XLE": ["XOM", "CVX", "COP", "SLB"],
    "XLI": ["CAT", "DE", "UNP", "HON", "GE", "RTX"],
    "XLP": ["PG", "KO", "PEP", "COST", "WMT"],
    "XLU": ["NEE", "DUK", "SO"],
    "XLB": ["LIN", "APD", "ECL"],
    "XLRE": ["AMT", "PLD", "CCI"],
}

# ä¸»é¢˜å…³é”®è¯åˆ°æ¿å—æ˜ å°„
THEME_SECTOR_MAP = {
    "ai": ["XLK", "XLC"],
    "nvidia": ["XLK"],
    "semiconductor": ["XLK"],
    "banking_crisis": ["XLP", "XLV", "XLU"],  # é¿é™©åˆ°é˜²å¾¡
    "rate_cuts": ["XLF", "XLRE", "XLY"],  # é™æ¯åˆ©å¥½
    "energy": ["XLE"],
    "oil": ["XLE"],
    "trump": ["XLF", "XLE", "XLI"],  # Trumpäº¤æ˜“
    "tariff": ["XLP", "XLV"],  # å…³ç¨Žé¿é™©åˆ°é˜²å¾¡
    "china": ["XLP", "XLV"],  # ä¸­ç¾Žç´§å¼ é¿é™©
    "crypto": ["XLF"],
    "deregulation": ["XLF"],
    "japan_carry": ["XLP", "XLV", "XLU"],  # å¥—æ¯å¹³ä»“é¿é™©
    "china_stimulus": ["XLB", "XLI"],  # ä¸­å›½åˆºæ¿€åˆ©å¥½
    "soft_landing": ["XLY", "XLF"],
    "data_center": ["XLK", "XLI"],
    "defense": ["XLI"],
    "healthcare": ["XLV"],
}

# åº”å›žé¿çš„æ¿å—æ˜ å°„
AVOID_SECTOR_MAP = {
    "banking_crisis": ["XLF"],
    "tariff": ["XLI", "XLY"],  # å…³ç¨Žå½±å“å·¥ä¸šå’Œæ¶ˆè´¹
    "china": ["XLK"],  # ç§‘æŠ€è„±é’©é£Žé™©
    "rates": ["XLRE", "XLU"],  # é«˜åˆ©çŽ‡å½±å“åœ°äº§å’Œå…¬ç”¨äº‹ä¸š
    "japan_carry": ["XLY", "XLF"],  # é£Žé™©èµ„äº§å›žé¿
}


class HistoricalThemeAnalyzer:
    """åŽ†å²å›žæµ‹ç‰ˆä¸»é¢˜åˆ†æžå™¨"""
    
    def __init__(self, cache_dir: Optional[Path] = None):
        self.cache_dir = cache_dir or Path("storage/intelligence_cache")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self._llm_cache: Dict[str, QuarterTheme] = {}
    
    def analyze_quarter_rule_based(self, quarter: str) -> QuarterTheme:
        """åŸºäºŽè§„åˆ™çš„å­£åº¦ä¸»é¢˜åˆ†æž"""
        events = get_quarter_events(quarter)
        if not events:
            return self._default_theme(quarter)
        
        hot_topics = events.get("hot_topics", [])
        narratives = events.get("leading_narratives", [])
        sentiment = events.get("market_sentiment", "")
        fed_policy = events.get("fed_policy", "")
        
        # æ”¶é›†ç„¦ç‚¹æ¿å—
        focus_sectors = []
        avoid_sectors = []
        
        for topic in hot_topics:
            if topic in THEME_SECTOR_MAP:
                focus_sectors.extend(THEME_SECTOR_MAP[topic])
            if topic in AVOID_SECTOR_MAP:
                avoid_sectors.extend(AVOID_SECTOR_MAP[topic])
        
        # æ ¹æ®Fedæ”¿ç­–è°ƒæ•´
        if "é™æ¯" in fed_policy or "rate_cuts" in hot_topics:
            focus_sectors.extend(["XLF", "XLRE"])
        if "åŠ æ¯" in fed_policy or "é«˜åˆ©çŽ‡" in sentiment:
            avoid_sectors.extend(["XLRE", "XLU"])
        
        # æ ¹æ®æƒ…ç»ªè°ƒæ•´
        if "è°¨æ…Ž" in sentiment or "é¿é™©" in sentiment:
            focus_sectors.extend(["XLP", "XLV", "XLU"])
            avoid_sectors.extend(["XLY"])
        if "ä¹è§‚" in sentiment:
            focus_sectors.extend(["XLK", "XLY"])
        
        # åŽ»é‡å¹¶æŽ’åº
        focus_sectors = list(dict.fromkeys(focus_sectors))[:4]
        avoid_sectors = list(dict.fromkeys([s for s in avoid_sectors if s not in focus_sectors]))[:3]
        
        # ç”Ÿæˆç„¦ç‚¹è‚¡ç¥¨
        focus_stocks = []
        for sector in focus_sectors:
            focus_stocks.extend(SECTOR_LEADERS.get(sector, [])[:2])
        
        # AIä¸»é¢˜ç‰¹æ®Šå¤„ç†
        if "ai" in hot_topics or "nvidia" in hot_topics:
            if "NVDA" not in focus_stocks:
                focus_stocks.insert(0, "NVDA")
            for s in ["AMD", "AVGO", "MSFT"]:
                if s not in focus_stocks:
                    focus_stocks.append(s)
        
        focus_stocks = list(dict.fromkeys(focus_stocks))[:8]
        
        # ç”Ÿæˆæ¿å—åŠ æˆ
        sector_bonus = {s: 3 - i for i, s in enumerate(focus_sectors)}
        
        # ç”Ÿæˆä¸»é¢˜åç§°
        theme = " + ".join(narratives[:2]) if narratives else "å¸‚åœºè§‚æœ›"
        
        reasoning = f"Fed: {fed_policy} | æƒ…ç»ª: {sentiment} | çƒ­ç‚¹: {', '.join(hot_topics[:3])}"
        
        return QuarterTheme(
            quarter=quarter,
            theme=theme,
            focus_sectors=focus_sectors,
            focus_stocks=focus_stocks,
            avoid_sectors=avoid_sectors,
            sector_bonus=sector_bonus,
            confidence="medium",
            reasoning=reasoning,
            source="rule",
        )
    
    def _default_theme(self, quarter: str) -> QuarterTheme:
        """é»˜è®¤ä¸»é¢˜é…ç½®"""
        return QuarterTheme(
            quarter=quarter,
            theme="å‡è¡¡é…ç½®",
            focus_sectors=["XLK", "XLV"],
            focus_stocks=["NVDA", "AAPL", "MSFT", "UNH"],
            avoid_sectors=[],
            sector_bonus={"XLK": 2, "XLV": 1},
            confidence="low",
            reasoning="æ— åŽ†å²æ•°æ®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®",
            source="rule",
        )
    
    def generate_llm_prompt(self, quarter: str) -> str:
        """ç”ŸæˆLLMåˆ†æžæç¤º"""
        events = get_quarter_events(quarter)
        if not events:
            return ""
        
        major_events = "\n".join(f"- {e}" for e in events.get("major_events", []))
        hot_topics = ", ".join(events.get("hot_topics", []))
        narratives = ", ".join(events.get("leading_narratives", []))
        sentiment = events.get("market_sentiment", "")
        fed_policy = events.get("fed_policy", "")
        
        prompt = f"""ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç¾Žè‚¡æŠ•èµ„ç­–ç•¥åˆ†æžå¸ˆã€‚è¯·åŸºäºŽä»¥ä¸‹ {quarter} çš„å¸‚åœºæƒ…æŠ¥ï¼Œè¿›è¡Œæ·±åº¦åˆ†æžå¹¶ç»™å‡ºæŠ•èµ„ä¸»é¢˜å»ºè®®ã€‚

## {quarter} å¸‚åœºæƒ…æŠ¥

### é‡å¤§äº‹ä»¶
{major_events}

### å¸‚åœºæƒ…ç»ª
{sentiment}

### Fed æ”¿ç­–
{fed_policy}

### çƒ­ç‚¹è¯é¢˜
{hot_topics}

### ä¸»å¯¼å™äº‹
{narratives}

## åˆ†æžè¦æ±‚

1. **å¸‚åœºå‘¨æœŸåˆ¤æ–­**: å½“å‰å¤„äºŽä»€ä¹ˆæ ·çš„å¸‚åœºå‘¨æœŸ?
2. **ä¸»é¢˜è¶‹åŠ¿**: ä¸»è¦æŠ•èµ„ä¸»é¢˜æ˜¯ä»€ä¹ˆ?
3. **æ¿å—é…ç½®**: å“ªäº›æ¿å—åº”è¯¥é‡ç‚¹é…ç½®? å“ªäº›åº”è¯¥å›žé¿?
4. **ä¸ªè‚¡é€‰æ‹©**: ç»™å‡º8åªé‡ç‚¹å…³æ³¨è‚¡ç¥¨

## è¾“å‡ºæ ¼å¼ (ä¸¥æ ¼æŒ‰æ­¤JSONæ ¼å¼)

```json
{{
  "market_cycle": "å¸‚åœºå‘¨æœŸåˆ¤æ–­",
  "theme": "æŠ•èµ„ä¸»é¢˜(ç®€æ´)",
  "focus_sectors": ["XLK", "XLE"],
  "focus_stocks": ["NVDA", "XOM", "CVX", "AAPL", "MSFT", "UNH", "JPM", "META"],
  "avoid_sectors": ["XLF"],
  "confidence": "high/medium/low",
  "reasoning": "åˆ†æžç†ç”±(2-3å¥è¯)"
}}
```

è¯·ç›´æŽ¥è¾“å‡ºJSONï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚
"""
        return prompt
    
    def parse_llm_response(self, quarter: str, response: str) -> Optional[QuarterTheme]:
        """è§£æžLLMå“åº”"""
        try:
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{[\s\S]*\}', response)
            if not json_match:
                return None
            
            data = json.loads(json_match.group())
            
            focus_sectors = data.get("focus_sectors", [])[:4]
            sector_bonus = {s: 3 - i for i, s in enumerate(focus_sectors)}
            
            return QuarterTheme(
                quarter=quarter,
                theme=data.get("theme", ""),
                focus_sectors=focus_sectors,
                focus_stocks=data.get("focus_stocks", [])[:8],
                avoid_sectors=data.get("avoid_sectors", [])[:3],
                sector_bonus=sector_bonus,
                confidence=data.get("confidence", "medium"),
                reasoning=data.get("reasoning", ""),
                source="llm",
            )
        except Exception as e:
            print(f"è§£æžLLMå“åº”å¤±è´¥: {e}")
            return None
    
    def analyze_all_quarters_rule_based(self) -> Dict[str, QuarterTheme]:
        """åˆ†æžæ‰€æœ‰å­£åº¦(è§„åˆ™æ¨¡å¼)"""
        results = {}
        for quarter in get_all_quarters():
            results[quarter] = self.analyze_quarter_rule_based(quarter)
        return results
    
    def export_themes_for_backtest(
        self, 
        themes: Dict[str, QuarterTheme]
    ) -> Dict[str, Dict]:
        """å¯¼å‡ºä¸»é¢˜é…ç½®ä¾›å›žæµ‹ä½¿ç”¨"""
        export = {}
        for quarter, theme in themes.items():
            export[quarter] = {
                "theme": theme.theme,
                "focus_sectors": theme.focus_sectors,
                "focus_stocks": theme.focus_stocks,
                "avoid_sectors": theme.avoid_sectors,
                "sector_bonus": theme.sector_bonus,
            }
        return export
    
    def save_analysis(self, themes: Dict[str, QuarterTheme], output_path: Path):
        """ä¿å­˜åˆ†æžç»“æžœ"""
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜å®Œæ•´åˆ†æž
        full_data = {
            quarter: {
                "quarter": t.quarter,
                "theme": t.theme,
                "focus_sectors": t.focus_sectors,
                "focus_stocks": t.focus_stocks,
                "avoid_sectors": t.avoid_sectors,
                "sector_bonus": t.sector_bonus,
                "confidence": t.confidence,
                "reasoning": t.reasoning,
                "source": t.source,
            }
            for quarter, t in themes.items()
        }
        
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(full_data, f, indent=2, ensure_ascii=False)
        
        print(f"åˆ†æžç»“æžœå·²ä¿å­˜åˆ°: {output_path}")
    
    def load_analysis(self, input_path: Path) -> Dict[str, QuarterTheme]:
        """åŠ è½½å·²ä¿å­˜çš„åˆ†æžç»“æžœ"""
        with open(input_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        themes = {}
        for quarter, t in data.items():
            themes[quarter] = QuarterTheme(
                quarter=t["quarter"],
                theme=t["theme"],
                focus_sectors=t["focus_sectors"],
                focus_stocks=t["focus_stocks"],
                avoid_sectors=t["avoid_sectors"],
                sector_bonus=t["sector_bonus"],
                confidence=t.get("confidence", "medium"),
                reasoning=t.get("reasoning", ""),
                source=t.get("source", "rule"),
            )
        return themes


def generate_llm_prompts_batch(output_dir: Path = None):
    """æ‰¹é‡ç”Ÿæˆæ‰€æœ‰å­£åº¦çš„LLMåˆ†æžæç¤º"""
    output_dir = output_dir or Path("storage/intelligence_cache/llm_prompts")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    analyzer = HistoricalThemeAnalyzer()
    
    print("=" * 60)
    print("æ‰¹é‡ç”Ÿæˆ LLM åˆ†æžæç¤º")
    print("=" * 60)
    
    all_prompts = []
    
    for quarter in get_all_quarters():
        prompt = analyzer.generate_llm_prompt(quarter)
        if prompt:
            # ä¿å­˜å•ä¸ªæç¤º
            prompt_file = output_dir / f"prompt_{quarter.replace('-', '_')}.txt"
            with open(prompt_file, "w", encoding="utf-8") as f:
                f.write(prompt)
            
            all_prompts.append(f"### {quarter}\n\n{prompt}\n")
            print(f"  âœ… {quarter} æç¤ºå·²ç”Ÿæˆ")
    
    # ä¿å­˜åˆå¹¶çš„æç¤º
    combined_file = output_dir / "all_prompts.md"
    with open(combined_file, "w", encoding="utf-8") as f:
        f.write("# æ‰€æœ‰å­£åº¦ LLM åˆ†æžæç¤º\n\n")
        f.write("\n---\n\n".join(all_prompts))
    
    print(f"\nðŸ“ æ‰€æœ‰æç¤ºå·²ä¿å­˜åˆ°: {output_dir}")
    print(f"ðŸ“„ åˆå¹¶æ–‡ä»¶: {combined_file}")


def analyze_all_rule_based():
    """ä½¿ç”¨è§„åˆ™æ¨¡å¼åˆ†æžæ‰€æœ‰å­£åº¦"""
    analyzer = HistoricalThemeAnalyzer()
    
    print("=" * 60)
    print("è§„åˆ™æ¨¡å¼åˆ†æžæ‰€æœ‰å­£åº¦")
    print("=" * 60)
    
    themes = analyzer.analyze_all_quarters_rule_based()
    
    for quarter, theme in themes.items():
        print(f"\n{quarter}:")
        print(f"  ä¸»é¢˜: {theme.theme}")
        print(f"  ç„¦ç‚¹æ¿å—: {', '.join(theme.focus_sectors)}")
        print(f"  ç„¦ç‚¹è‚¡ç¥¨: {', '.join(theme.focus_stocks[:5])}...")
        print(f"  å›žé¿æ¿å—: {', '.join(theme.avoid_sectors) if theme.avoid_sectors else 'æ— '}")
    
    # ä¿å­˜ç»“æžœ
    output_path = Path("storage/intelligence_cache/rule_based_themes.json")
    analyzer.save_analysis(themes, output_path)
    
    # å¯¼å‡ºå›žæµ‹é…ç½®
    backtest_config = analyzer.export_themes_for_backtest(themes)
    config_path = Path("storage/intelligence_cache/backtest_themes.json")
    with open(config_path, "w", encoding="utf-8") as f:
        json.dump(backtest_config, f, indent=2, ensure_ascii=False)
    print(f"\nå›žæµ‹é…ç½®å·²ä¿å­˜åˆ°: {config_path}")
    
    return themes


if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "--prompts":
        generate_llm_prompts_batch()
    else:
        analyze_all_rule_based()
